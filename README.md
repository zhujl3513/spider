# 股票财务数据爬虫

## 项目简介

这是一个全面升级的股票财务数据爬虫工具，支持从多个数据源获取A股全市场股票的财务数据和市场指标。工具提供了高效的数据采集、处理和保存功能，支持批量获取和自定义股票查询。

## 主要特性

1. **多数据源支持**：集成东方财富、AKShare等多个数据源，支持自动切换和冗余备份
2. **全市场覆盖**：支持A股全市场5000+股票的批量爬取，包括主板、创业板、科创板
3. **高效并行处理**：使用多线程技术大幅提升数据获取效率
4. **智能错误处理**：完善的错误处理和重试机制，确保长时间稳定运行
5. **灵活配置**：支持自定义线程数、请求延迟等参数

## 环境要求

- Python 3.13.5
- Ubuntu 24.04 (也支持Windows系统)
- 稳定的网络连接

## 安装部署

### 1. 克隆或下载项目文件

```bash
mkdir stock_crawler_enhanced && cd stock_crawler_enhanced
# 将Python文件放置在此目录下
```

### 2. 创建Python虚拟环境（推荐）

```bash
# 安装虚拟环境工具
sudo apt install python3-venv

# 创建虚拟环境
python3 -m venv venv

# 激活虚拟环境
source venv/bin/activate
```

### 3. 安装依赖库

创建requirements.txt文件，内容如下：

```txt
requests>=2.31.0
pandas>=2.0.0
openpyxl>=3.1.0
akshare>=1.12.75
concurrent-log-handler>=0.9.20
tqdm>=4.66.0
```

然后安装依赖：

```bash
pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/
```

### 4. 运行程序

```bash
python spider.py
```

## 使用说明

### 模式选择

程序启动后提供三种模式选择：

1. **全市场爬取模式**：爬取A股全市场所有股票数据
2. **指定市场爬取模式**：选择特定市场（主板、创业板、科创板）进行爬取
3. **自定义查询模式**：输入特定股票代码进行查询

### 并行处理功能

#### 功能特点

1. **多线程并行处理**：使用`ThreadPoolExecutor`实现多线程并行处理
2. **线程安全**：添加了`print_lock`确保多线程环境下的打印安全
3. **灵活配置**：允许用户自定义线程数量
4. **性能优化**：并行处理时减少了单个请求的延时

#### 使用建议

- **线程数设置**：建议设置为10-20之间，过高可能导致服务器拒绝服务
- **适用场景**：处理大量股票数据时（如全市场5000+股票）效果明显
- **注意事项**：并行处理会增加网络请求频率，需要合理控制线程数避免被服务器限制

#### 配置示例

```python
# 在代码中设置线程数
crawler.run(use_parallel=True, max_workers=15)

# 或者在运行时选择
是否使用并行处理？(y/N): y
请输入线程数（建议10-20）: 15
```

### 数据源配置

程序支持多数据源，默认配置为：
1. AKShare (优先级1)
2. 东方财富 (优先级2)

可以在代码中的`data_sources`配置中启用或禁用数据源，调整优先级。

### 数据输出

程序会自动创建`stock_data_spider`目录，并将数据保存为以下格式：
- 各市场单独CSV文件：`市场名_财务数据_时间戳.csv`
- 所有市场汇总Excel文件：`所有市场股票财务数据_时间戳.xlsx`

### 性能优化建议

1. **合理设置线程数**：根据网络状况和目标服务器限制调整线程数
2. **控制请求频率**：适当增加请求延迟，避免被反爬机制限制
3. **分批处理**：大量数据时使用分批处理，减少内存占用
4. **使用代理IP**：如果需要大量请求，考虑使用代理IP池

## 编译为可执行文件

### 在Ubuntu系统上编译

```bash
pip install pyinstaller
pyinstaller --onefile --name stock_crawler_enhanced spider.py
```

### 在Windows系统上编译

```bat
pip install pyinstaller
pyinstaller --onefile --name stock_crawler_enhanced.exe spider.py
```

## 故障排除与优化

### 常见问题

1. **东方财富接口返回HTML**：可能是请求头不完整或被反爬机制限制，尝试：
    - 更新请求头信息
    - 增加请求延迟
    - 使用代理IP

2. **AKShare接口失败**：检查AKShare版本和网络连接

3. **内存不足**：减少批量处理大小或增加系统内存

### 性能优化

1. **调整线程数**：根据网络状况和目标服务器响应调整并行线程数
2. **合理设置延迟**：在请求频率和爬取速度之间找到平衡点
3. **使用缓存**：对已获取的数据进行缓存，避免重复请求
4. **分时段爬取**：在服务器负载较低时段进行大规模爬取

### 日志分析

程序会生成详细的日志文件`stock_crawler.log`，包含：
- 请求详情和响应状态
- 错误信息和堆栈跟踪
- 性能统计和处理进度

## 注意事项

1. **遵守法律法规**：请遵守相关法律法规，合理使用爬取的数据
2. **尊重网站规则**：遵守目标网站的robots.txt协议和使用条款
3. **控制请求频率**：避免对目标服务器造成过大负担
4. **数据准确性**：重要决策前请验证数据的准确性和时效性

## 更新日志

- 2024-08-28: 增强并行处理功能，添加线程安全机制
- 2024-08-27: 全面优化版本发布，支持多数据源和全市场爬取
- 2024-08-20: 初始版本发布，支持主板、创业板、科创板数据爬取

## 技术支持

如遇到问题，请检查：
1. Python版本是否为3.13.5
2. 所有依赖库是否已正确安装
3. 网络连接是否正常
4. 目标网站是否可以正常访问

如果问题仍无法解决，请提供详细的错误信息以便进一步分析。
